{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleaning\n",
    "We are going to do data cleaning on the MSR-VTT dataset in three steps: \n",
    "- Remove special characters.\n",
    "- Correct spelling mistakes.\n",
    "- Remove duplicated annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile as zf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human annotations from compressed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zf.ZipFile(\"train_val_annotation.zip\", \"r\") as myzip:\n",
    "    train_val = json.load(myzip.open(\"train_val_videodatainfo.json\"))\n",
    "    \n",
    "with zf.ZipFile(\"test_videodatainfo.json.zip\", \"r\") as myzip:\n",
    "    test = json.load(myzip.open(\"test_videodatainfo.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence number in the training set: 130260\n",
      "Sentence number in the validation set: 9940\n",
      "Sentence in the testing set: 59800\n"
     ]
    }
   ],
   "source": [
    "train_val_sentences = train_val['sentences']\n",
    "test_sentences = test['sentences']\n",
    "\n",
    "train_sents = []\n",
    "for s in train_val_sentences:\n",
    "    if int(s['video_id'][5:]) < 6513:\n",
    "        train_sents.append(s)\n",
    "\n",
    "print('Sentence number in the training set:', len(train_sents))\n",
    "        \n",
    "val_sents = []\n",
    "for s in train_val_sentences:\n",
    "    idx = int(s['video_id'][5:])\n",
    "    if 6513 <= idx < 7010:\n",
    "        val_sents.append(s)\n",
    "        \n",
    "print('Sentence number in the validation set:', len(val_sents))\n",
    "\n",
    "test_sents = test_sentences\n",
    "print('Sentence in the testing set:', len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count in the training set: 1207727\n",
      "Word count in the validation set: 91689\n",
      "Word count in the testing set: 557105\n"
     ]
    }
   ],
   "source": [
    "train_word_cnt = 0\n",
    "\n",
    "for s in train_sents:\n",
    "    s = s['caption']\n",
    "    train_word_cnt += len(s.strip().split())\n",
    "\n",
    "print('Word count in the training set:', train_word_cnt)\n",
    "\n",
    "val_word_cnt = 0\n",
    "for s in val_sents:\n",
    "    s = s['caption']\n",
    "    val_word_cnt += len(s.strip().split())\n",
    "print('Word count in the validation set:', val_word_cnt)\n",
    "\n",
    "test_word_cnt = 0\n",
    "for s in test_sents:\n",
    "    s = s['caption']\n",
    "    test_word_cnt += len(s.strip().split())\n",
    "    \n",
    "print('Word count in the testing set:', test_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size in the training set: 23666\n",
      "Vocabulary size in the validation set: 5993\n",
      "Vocabulary size in the testing set: 16001\n"
     ]
    }
   ],
   "source": [
    "def get_word_set(dataset):\n",
    "    word_set = set()\n",
    "    for s in dataset:\n",
    "        caption = s['caption']\n",
    "        words = caption.strip().split()\n",
    "        word_set |= set(words)\n",
    "    return word_set\n",
    "\n",
    "train_word_set = get_word_set(train_sents)\n",
    "val_word_set = get_word_set(val_sents)\n",
    "test_word_set = get_word_set(test_sents)\n",
    "\n",
    "print('Vocabulary size in the training set: {}'.format(len(train_word_set)))\n",
    "print('Vocabulary size in the validation set: {}'.format(len(val_word_set)))\n",
    "print('Vocabulary size in the testing set: {}'.format(len(test_word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sentence length distribution')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_len_list = []\n",
    "for s in train_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "for s in val_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "for s in test_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sent_len_list, list(range(0, 36, 2)), facecolor='g')\n",
    "plt.xlabel('Sentence length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentence length distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the mapping from video to captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos in total: 10000, videos in the training set: 6513, videos in the validation set: 497, videos in the testing set: 2990.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "video2caption = defaultdict(lambda:[])\n",
    "train_set, val_set, test_set = defaultdict(lambda:[]), defaultdict(lambda:[]), defaultdict(lambda:[])\n",
    "\n",
    "for s in train_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    caption = s['caption']\n",
    "    video2caption[vidx].append(caption)\n",
    "    train_set[vidx].append(caption)\n",
    "    \n",
    "for s in val_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    caption = s['caption']\n",
    "    video2caption[vidx].append(caption)\n",
    "    val_set[vidx].append(caption)\n",
    "    \n",
    "for s in test_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    caption = s['caption']\n",
    "    video2caption[vidx].append(caption)\n",
    "    test_set[vidx].append(caption)\n",
    "\n",
    "print('Videos in total: {}, videos in the training set: {}, videos in the validation set: {}, videos in the testing set: {}.'.\n",
    "      format(len(video2caption), len(train_set), len(val_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters\n",
    "\n",
    "Firstly, we will show all the characters existing in the dataset. And then, we try to remove the peculiar ones in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: ['#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', '>', '@', '[', '\\\\', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'é', 'в', '’']\n",
      "Character count: 60\n"
     ]
    }
   ],
   "source": [
    "def get_charset(video2caption):\n",
    "    charset = set()\n",
    "\n",
    "    for vid in video2caption:\n",
    "        captions = video2caption[vid]\n",
    "        for caption in captions:\n",
    "            words = caption.strip().split()\n",
    "            for word in words:\n",
    "                charset |= set(list(word))\n",
    "    return charset\n",
    "\n",
    "charset = get_charset(video2caption)\n",
    "print('Characters: {}'.format(sorted(list(charset))))\n",
    "print('Character count: {}'.format(len(charset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"#\", \"*\", \"+\", \".\", \":\", \"=\", \">\", \"\\\\\" are removed from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set examples.\n",
      "Example for '=': an audience watching a group of performet=rs\n",
      "Example for ':': scenes from the movie avengers: age of ultron\n",
      "Example for '\\': an individual describing\\ what he is seeing on his screen\n",
      "Example for '#': reactions to sports vine #20\n",
      "Example for '+': ted ideas worth spreading one of 1000+ ted talks\n",
      "Example for '*': a vehicle on a city road passes a blue car speeding down the road*\n",
      "\n",
      "\n",
      "Validation set examples.\n",
      "Example for '#': com clip from a list and #8 on that list is nicholas brody from homeland (2011) followed by a spooky scary pirate face\n",
      "Example for ':':  annie leblanc  had a huge victory yesterday in the 1660m race with a final time of 4:16\n",
      "\n",
      "\n",
      "Testing set examples.\n",
      "Example for ':': three children battle on the voice kids: philippines\n",
      "Example for '#': entry #10 from a top list showing a play from an nfl game\n",
      "Example for '>': sports highlights are shown on tv>\n",
      "Example for '.': a woman is dacning in the clip.\n",
      "Example for '=': an animation of a black an =d white dog is given food by his owner and he is excited to eat his food\n",
      "Example for '\\': a big fish catch the man in sea while he swimming\\\n",
      "Example for '+': an advertisement about ted talks a new ideas in every weekday is one of the thousands +\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "origin_chars = [\"#\", \"*\", \".\", \":\", \"+\", \"=\", \">\", \"\\\\\"]\n",
    "\n",
    "def show_examples(data_set, chars):\n",
    "    for vidx, sents in data_set.items():\n",
    "        for sent in sents:\n",
    "            for c in chars:\n",
    "                if c in sent:\n",
    "                    print(\"Example for '{}': {}\".format(c, sent))\n",
    "                    chars.remove(c)\n",
    "                    break\n",
    "            \n",
    "            \n",
    "chars = copy.deepcopy(origin_chars)\n",
    "print('Training set examples.')\n",
    "show_examples(train_set, chars)\n",
    "        \n",
    "print('\\n\\nValidation set examples.')\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "show_examples(val_set, chars)\n",
    "        \n",
    "        \n",
    "print('\\n\\nTesting set examples.')\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "show_examples(test_set, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video2caption_step1 = defaultdict(lambda: [])\n",
    "\n",
    "for vidx, sents in video2caption.items():\n",
    "    new_sents = []\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent.replace(\"#\", \"\")\n",
    "        new_sent = new_sent.replace(\"*\", \"\")\n",
    "        new_sent = new_sent.replace(\"+\", \"\")\n",
    "        new_sent = new_sent.replace(\".\", \"\")\n",
    "        new_sent = new_sent.replace(\":\", \"\")\n",
    "        new_sent = new_sent.replace(\"=\", \"\")\n",
    "        new_sent = new_sent.replace(\">\", \"\")\n",
    "        new_sent = new_sent.replace(\"\\\\\", \"\")\n",
    "        new_sents.append(new_sent)\n",
    "    new_video2caption_step1[vidx] = new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_1_videodatainfo.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\[\\]\"s and \"()\"s will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = re.sub(r\"\\[[\\w \\d/-]+\\]\", \"\", sent)\n",
    "        if new_sent != sent:\n",
    "            new_sent = \" \".join(new_sent.split())\n",
    "            new_video2caption_step1[vidx][sidx] = new_sent\n",
    "            \n",
    "            \n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = re.sub(r\"\\([\\w \\d/-]+\\)\", \"\", sent)\n",
    "        if new_sent != sent:\n",
    "            new_sent = \" \".join(new_sent.split())\n",
    "            new_video2caption_step1[vidx][sidx] = new_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some examples for '\\[' or '\\]' or '(' that appear in the sentences alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two kids are having fun in water]\n",
      "a video of agriculture production]\n",
      " asc (academy-award winning cinematographer speaking about an film\n",
      "man and women getting physical or intimate cuts to a scene of shampoo or lotion dripping out of the bottle (implying i am guessing climax\n",
      "a scene from the movie girls just wanna have fun featuring a male dancer supporting his female partner in a one-armed lift on a dancing tv show as another couple (including actress\n",
      "a man p[laying golf \n",
      "a man with hair is sitting in a p[lace\n",
      "the crazy train ( reed streets  music  with soft ball players in white bottoms and blue tops \n"
     ]
    }
   ],
   "source": [
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        if '[' in sent or ']' in sent or '(' in sent or ')' in sent:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\[\"s, \"\\]\"s, \"\\(\"s,  that are single, will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cnt = 0\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent.replace(\"[\", \"\")\n",
    "        new_sent = new_sent.replace(\"]\", \"\")\n",
    "        new_sent = new_sent.replace(\"(\", \"\")\n",
    "        new_video2caption_step1[vidx][sidx] = new_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_2_videodatainfo.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"-\", \"|\", \"'\", \"\\`\", \"\\@\", \"\\_\", \"\\/\" are replace by a space \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for '-': three contestants and host prepare for a low-budget game show\n",
      "Example for '/': someone working on a drawing in ms paint/\n",
      "Example for '@': an advertisement is displayed for the @mattsteffanina twitter profile featuring ariana grande jason derulo and tyga\n",
      "Example for '_': drums are played in the background music video is shown of a small white car in a rural setting the title is travel vlog_1 wicklow\n",
      "Example for '’': visions of apples are portrayed as a woman’s voice comments on the benefits of apples\n"
     ]
    }
   ],
   "source": [
    "origin_chars = [\"-\", \"|\", \"‘\", \"’\", \"@\", \"_\", \"/\"]\n",
    "\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "\n",
    "show_examples(train_set, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent.replace(\"-\", \" \")\n",
    "        new_sent = new_sent.replace(\"|\", \" \")\n",
    "        new_sent = new_sent.replace(\"‘\", \" \")\n",
    "        new_sent = new_sent.replace(\"’\", \" \")\n",
    "        new_sent = new_sent.replace(\"@\", \" \")\n",
    "        new_sent = new_sent.replace(\"_\", \" \")\n",
    "        new_sent = new_sent.replace(\"/\", \" \")\n",
    "        new_sent = \" \".join(new_sent.split())\n",
    "        new_video2caption_step1[vidx][sidx] = new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_3_videodatainfo.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'é', 'в' are replaced by \"e\" and \"b\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vidx, sents  in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent.replace('é', 'e')\n",
    "        new_sent = new_sent.replace('в', 'b')\n",
    "        new_video2caption_step1[vidx][sidx] = new_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "' & 's are substituted by 'and'. And '&'s that are part of words, are not replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        if ' & ' in sent:\n",
    "            new_sent = sent.replace(' & ', ' and ')\n",
    "            new_sent = ' '.join(new_sent.split())\n",
    "            new_video2caption_step1[vid][sidx] = new_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'\\`s' will be replaced by ' s', otherwise it will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent.replace('`s', ' s')\n",
    "        new_sent = new_sent.replace('`', '')\n",
    "        new_sent = \" \".join(new_sent.split())\n",
    "        new_video2caption_step1[vid][sidx] = new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7247 sentences have been modified in this section.\n",
      "new character set: {'d', '1', '4', 'p', 'k', 'y', '$', 'z', 'i', '7', '9', '8', 'h', '5', 'u', 'r', '&', 'j', 'w', 's', 'v', '6', 'x', 'c', 'f', 'q', 'o', 'g', 'm', '0', 'a', '3', 'b', '2', '%', 't', 'l', 'n', 'e'}, cnt: 39\n"
     ]
    }
   ],
   "source": [
    "with open(\"step1_videodatainfo.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)\n",
    "    \n",
    "cnt = 0\n",
    "for vidx, sents in video2caption.items():\n",
    "    for sidx in range(len(sents)):\n",
    "        if video2caption[vidx][sidx] != new_video2caption_step1[vidx][sidx]:\n",
    "            cnt += 1\n",
    "            \n",
    "print('{} sentences have been modified in this section.'.format(cnt))\n",
    "\n",
    "new_charset = get_charset(new_video2caption_step1)\n",
    "print('new character set: {}, cnt: {}'.format(new_charset, len(new_charset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct spelling mistakes\n",
    "In this section, we are going to correct some spelling mistakes detected by `HunSpell`.\n",
    "\n",
    "Firstly, we substitute British English spellings with American English ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 1: a man gets hit in the face with a chair during a wwf wrestling match -> a man gets hit in the face with a chair during a wwe wrestling match\n",
      "example 2: a man is hitting another man with chair in wwf -> a man is hitting another man with chair in wwe\n",
      "example 3: this is a wwf wrestling match -> this is a wwe wrestling match\n",
      "example 4: a man gets hit in the face with a chair during a wwf wrestling match -> a man gets hit in the face with a chair during a wwe wrestling match\n",
      "example 5: some womens are making fun -> some women are making fun\n",
      "example 6: womans make fun while get together -> woman make fun while get together\n",
      "example 7: some womens are making fun -> some women are making fun\n",
      "example 8: a woman is modelling for a piece of clothing -> a woman is modeling for a piece of clothing\n",
      "example 9: a woman is modelling for a piece of clothing -> a woman is modeling for a piece of clothing\n",
      "example 10: there is a man who met another man in this video and he is also travelling in a car -> there is a man who met another man in this video and he is also traveling in a car\n",
      "Replace count: 1880.\n"
     ]
    }
   ],
   "source": [
    "with open('english_america.txt', 'r') as fo:\n",
    "    lines = fo.readlines()\n",
    "english2america = {}\n",
    "for line in lines:\n",
    "    word1, word2 = line.strip().split(' -> ')\n",
    "    english2america[word1] = word2\n",
    "    \n",
    "cnt = 0\n",
    "print_cnt = 0\n",
    "\n",
    "new_video2caption_step2 = defaultdict(lambda: [])\n",
    "\n",
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        words = sent.strip().split()\n",
    "        for widx, word in enumerate(words):\n",
    "            if word in english2america:\n",
    "                words[widx] = english2america[word]\n",
    "                cnt += 1\n",
    "        new_sent = \" \".join(words)\n",
    "        if new_video2caption_step1[vid][sidx] != new_sent and print_cnt < 10:\n",
    "            print_cnt += 1\n",
    "            print(\"example {}: {} -> {}\".format(print_cnt, new_video2caption_step1[vid][sidx], new_sent))\n",
    "    \n",
    "        new_video2caption_step2[vid].append(\" \".join(words))\n",
    "        \n",
    "print('Replace count: {}.'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we split words that are composed of two individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: a clip from dragonball z -> a clip from dragon ball z\n",
      "sample 2: a dragonball z scene where a bold man yells kamehame ya -> a dragon ball z scene where a bold man yells kamehame ya\n",
      "sample 3: video game characters are passing by eachother -> video game characters are passing by each other\n",
      "sample 4: a third person videogame character walking into a poke center in the pokemon game -> a third person video game character walking into a poke center in the pokemon game\n",
      "sample 5: a woman talking on talkshow -> a woman talking on talk show\n",
      "sample 6: gameplay of a videogame is shown -> gameplay of a video game is shown\n",
      "sample 7: pokemon character walking in the pokecenter -> pokemon character walking in the pokemon center\n",
      "sample 8: someone is playing pokemon on a gameboy -> someone is playing pokemon on a game boy\n",
      "sample 9: someone playing pokemon on gameboy -> someone playing pokemon on game boy\n",
      "sample 10: a third person videogame character walking into a poke center in the pokemon game -> a third person video game character walking into a poke center in the pokemon game\n",
      "Replace count: 934.\n"
     ]
    }
   ],
   "source": [
    "with open('split.txt', 'r') as fo:\n",
    "    lines = fo.readlines()\n",
    "split_dict = {}\n",
    "for line in lines:\n",
    "    word1, word2 = line.strip().split(' -> ')\n",
    "    split_dict[word1] = word2\n",
    "    \n",
    "cnt = 0\n",
    "print_cnt = 0\n",
    "for vidx, sents in new_video2caption_step2.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        words = sent.strip().split()\n",
    "        for widx, word in enumerate(words):\n",
    "            if word in split_dict:\n",
    "                words[widx] = split_dict[word]\n",
    "                cnt += 1\n",
    "        new_sent = \" \".join(words)\n",
    "        if print_cnt < 10 and new_video2caption_step2[vidx][sidx] != new_sent:\n",
    "            print_cnt += 1\n",
    "            print('sample {}: {} -> {}'.format(print_cnt, new_video2caption_step2[vidx][sidx], new_sent))\n",
    "            \n",
    "        new_video2caption_step2[vidx][sidx] = new_sent\n",
    "        \n",
    "print('Replace count: {}.'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, we correct words using hunspell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32056 words have been corrected.\n"
     ]
    }
   ],
   "source": [
    "import hunspell\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "ParallelNum = 32\n",
    "\n",
    "spellchecker = hunspell.HunSpell('/usr/share/hunspell/en_US.dic', '/usr/share/hunspell/en_US.aff')\n",
    "\n",
    "with open('dictionary.txt', 'r') as fo:\n",
    "    words = fo.readlines()\n",
    "    words = [w.strip() for w in words]\n",
    "\n",
    "for w in words:\n",
    "    spellchecker.add(w)\n",
    "    \n",
    "def correct_words(words):\n",
    "    ret_words = []\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if spellchecker.spell(word):\n",
    "            ret_words.append(word)\n",
    "        else:\n",
    "            suggestions = spellchecker.suggest(word)\n",
    "            if len(suggestions) > 0:\n",
    "                ret_words.append(suggestions[0])\n",
    "                count += 1\n",
    "            else:\n",
    "                ret_words.append(word)\n",
    "    return ret_words, count\n",
    "\n",
    "def correct_videos(video2caption):\n",
    "    cnt = 0\n",
    "    for vidx, captions in video2caption.items():\n",
    "        for sidx, caption in enumerate(captions):\n",
    "            words, c = correct_words(caption.strip().split())\n",
    "            cnt += c\n",
    "            video2caption[vidx][sidx] = \" \".join(words).lower()\n",
    "    return video2caption, cnt\n",
    "\n",
    "cnt = 0\n",
    "with mp.Pool(ParallelNum) as pool:\n",
    "    video_list = [{} for _ in range(ParallelNum)]\n",
    "    for vidx, captions in new_video2caption_step2.items():\n",
    "        video_list[vidx%ParallelNum][vidx] = captions\n",
    "    \n",
    "    results = []\n",
    "    for idx in range(ParallelNum):\n",
    "        results += [pool.apply_async(correct_videos, [video_list[idx]])]\n",
    "    results = [r.get() for r in results]\n",
    "    \n",
    "for r in results:\n",
    "    videos = r[0]\n",
    "    cnt += r[1]\n",
    "    for key in videos:\n",
    "        new_video2caption_step2[key] = videos[key]\n",
    "        \n",
    "print('{} words have been corrected.'.format(cnt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample ten videos randomly and check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a couple of guys are rapping in a video\n",
      "a rapper dances around for a music video\n",
      "a stream bubbles over rocks surrounded by green trees\n",
      "some one showing the beautiful scene of the nature\n",
      "a girl is rapping with olive oil in her hand\n",
      "a girl is singing in a kitchen about avocados and olive oil\n",
      "a group of alpacas eating plants in some kind of exhibit\n",
      "alpacas like to eat egress and hey\n",
      "a black and white video of an old chevrolet\n",
      "a car drives along a road\n",
      "a cartoon of caterpillars\n",
      "a clip of adventure time from cartoon network\n",
      "mountains and trees covered with snow and a small water fall\n",
      "a frozen mountain melts as the year warms up\n",
      "a half naked man is swimming in a lake\n",
      "a man swims to his surfboard in a chick beneath a bridge\n",
      "there is a man with specs is watching through the camera\n",
      "there is a man with specs is watching through the camera\n",
      "freshly cooked plate of shrimp stir fry using udon noodles\n",
      "prepared food are nicely put in plate in a table\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    idx = random.randint(0, 10000)\n",
    "    print(*new_video2caption_step2[idx][:2], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step2_videodatainfo.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step2, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated annotations\n",
    "Now, we are going to remove duplicated annotations.\n",
    "\n",
    "Here is the function used to compute sentence similarity with edit distance as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "import numpy as np\n",
    "\n",
    "ED_THRESHOLD = 0\n",
    "\n",
    "def sentence_similarity(sent1, sent2):\n",
    "    words1 = sent1.strip().split()\n",
    "    words2 = sent2.strip().split()\n",
    "    \n",
    "    dp_mat = np.zeros(shape=(len(words1)+1, len(words2)+1), dtype=int)\n",
    "    for idx1 in range(len(words1)):\n",
    "        for idx2 in range(len(words2)):\n",
    "            w_dist = edit_distance(words1[idx1], words2[idx2])\n",
    "            dist0 = dp_mat[idx1, idx2] + (1 if w_dist<=ED_THRESHOLD else 0)\n",
    "            dp_mat[idx1+1, idx2+1] = max(dist0, dp_mat[idx1, idx2+1], dp_mat[idx1+1, idx2])\n",
    "    lcs = dp_mat[len(words1), len(words2)]\n",
    "    similarity = 0.5 * (lcs / len(words1) + lcs / len(words2))\n",
    "    \n",
    "    return similarity, lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example for sentence similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8263888888888888, 7)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"a woman is singing on a music video\"\n",
    "sent2 = \"a young woman is singing in a music video\"\n",
    "\n",
    "sentence_similarity(sent1, sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182264 captions remain.\n"
     ]
    }
   ],
   "source": [
    "Threshold = 0.85\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "def remove_duplicate_captions(video2caption):\n",
    "    cnt = 0\n",
    "    for vidx, captions in video2caption.items():\n",
    "        similar_captions = defaultdict(list)\n",
    "        inserted = np.zeros(shape=(len(captions),), dtype=int)\n",
    "        for cidx1 in range(len(captions)):\n",
    "            if inserted[cidx1]:\n",
    "                continue\n",
    "            similar_captions[cidx1].append(captions[cidx1])\n",
    "            inserted[cidx1] = 1\n",
    "            for cidx2 in range(cidx1 + 1, len(captions)):\n",
    "                if inserted[cidx2]:\n",
    "                    continue\n",
    "\n",
    "                simil, _ = sentence_similarity(captions[cidx1], captions[cidx2])\n",
    "                if simil >= Threshold:\n",
    "                    similar_captions[cidx1].append(captions[cidx2])\n",
    "                    inserted[cidx2] = 1\n",
    "        \n",
    "        new_captions = [sorted(cs, key=lambda x: len(x), reverse=True)[0] for _, cs in similar_captions.items()]\n",
    "        cnt += len(new_captions)\n",
    "        video2caption[vidx] = new_captions\n",
    "\n",
    "    return video2caption, cnt\n",
    "\n",
    "videos_list = [{} for _ in range(ParallelNum)]\n",
    "for vidx, captions in new_video2caption_step2.items():\n",
    "    videos_list[vidx%ParallelNum][vidx] = captions\n",
    "\n",
    "with mp.Pool(ParallelNum) as pool:\n",
    "    rlist = []\n",
    "    for vl in videos_list:\n",
    "        rlist.append(pool.apply_async(remove_duplicate_captions, [vl]))\n",
    "    rlist = [r.get() for r in rlist]\n",
    "\n",
    "new_video2caption_step3 = defaultdict(list)\n",
    "\n",
    "for v, c in rlist:\n",
    "    cnt += c\n",
    "    new_video2caption_step3.update(v)\n",
    "    \n",
    "    \n",
    "print('{} captions remain.'.format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_videodatainfo_prob_85.json', 'w') as fo:\n",
    "    json.dump(new_video2caption_step3, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 118549, validation count: 9062, test count: 54653.\n"
     ]
    }
   ],
   "source": [
    "train_cnt, val_cnt, test_cnt = 0, 0, 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step3.items():\n",
    "    if vidx < 6513:\n",
    "        train_cnt += len(sents)\n",
    "    elif vidx < 7010:\n",
    "        val_cnt += len(sents)\n",
    "    else:\n",
    "        test_cnt += len(sents)\n",
    "        \n",
    "print('Train count: {}, validation count: {}, test count: {}.'.format(train_cnt, val_cnt, test_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum caption count is 8, maximum caption count is 20.\n"
     ]
    }
   ],
   "source": [
    "min_cnt, max_cnt = 1000, 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step3.items():\n",
    "    min_cnt = min(min_cnt, len(sents))\n",
    "    max_cnt = max(max_cnt, len(sents))\n",
    "\n",
    "print('minimum caption count is {}, maximum caption count is {}.'.format(min_cnt, max_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify redundant sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.477378966773472 9.0 4.326609953357923\n",
      "7531 2778 976\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "avg_sen_len_list = []\n",
    "\n",
    "\n",
    "for key, val in new_video2caption_step3.items():\n",
    "    for sen in val:\n",
    "        avg_sen_len_list += [len(sen.strip().split())]\n",
    "    \n",
    "        \n",
    "print(np.mean(avg_sen_len_list), np.median(avg_sen_len_list), np.std(avg_sen_len_list))\n",
    "avg_len, std_len = np.mean(avg_sen_len_list), np.std(avg_sen_len_list)\n",
    "cnt2, cnt3, cnt4 = 0, 0, 0\n",
    "\n",
    "for length in avg_sen_len_list:\n",
    "    if length > avg_len + 2 * std_len:\n",
    "        cnt2 += 1\n",
    "        \n",
    "    if length > avg_len + 3 * std_len:\n",
    "        cnt3 += 1\n",
    "        \n",
    "    if length > avg_len + 4 * std_len:\n",
    "        cnt4 += 1\n",
    "        \n",
    "print(cnt2, cnt3, cnt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9216, 2, a clip from the music video for this is how we roll a country song that features dirt bikes miraculously not driving right through the band standing on the top of the ramp',\n",
       " '8512, 4, a man is giving information on how bicycling and swimming burns calories he is stating that they both burn calories but it varies on the difficulty level',\n",
       " '9472, 2, a girl wearing a dress stands to the side of the screen while lyrics to a song playing in the background appear on the other side',\n",
       " '7616, 11, an orange lamborghini revs its engine and is speeding onto a street and then a black lamborghini is shown pulling up to a stop sign',\n",
       " '8128, 0, a cartoon character from the spongebob squarepants speaks to the audience but no sounds is heard and then he gets on a bicycle and dons some sort of a hat that looks like a water glass and rides away all the while a subtitle can be read on the lower left side of the screen saying extremity',\n",
       " '9056, 4, a british man driving a red car parks and upon switching the gear into reverse a rear camera pops out of the back of the car',\n",
       " '9056, 11, a man in a car is giving a review on a volkswagen car the car is red with what seems to be a leather interior',\n",
       " '9056, 18, a man on the wheels talking about the easiness of parking and the camera coming out of the logo when reverse gear is on for volkswagen polo',\n",
       " '9120, 8, in a black helmet and ski outfit is leaning forward and holding onto a white pole that is quickly pulling her over a field of snow',\n",
       " '9088, 9, a man in the blue shirt in the water with a surfboard and a shark fin near him right before he goes under']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_sentences = []\n",
    "\n",
    "for vid, sentences in new_video2caption_step3.items():\n",
    "    if vid < 7010:\n",
    "        continue\n",
    "\n",
    "    for sid, sentence in enumerate(sentences):\n",
    "        words = sentence.strip().split()\n",
    "        if len(words) > avg_len + 3 * std_len:\n",
    "            multiple_sentences.append(\"{}, {}, {}\".format(vid, sid, sentence))\n",
    "            \n",
    "print(len(multiple_sentences))\n",
    "multiple_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"multiple_sentences.txt\", \"w\") as fo:\n",
    "    for line in multiple_sentences:\n",
    "        fo.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9216, 2, a clip from the music video for this is how we roll a country song that features dirt bikes miraculously not driving right through the band standing on the top of the ramp',\n",
       " '8512, 4, a man is giving information on how bicycling and swimming burns calories',\n",
       " '9472, 2, a girl wearing a dress stands to the side of the screen while lyrics to a song playing in the background appear on the other side',\n",
       " '7616, 11, an orange lamborghini revs its engine and is speeding onto a street and then a black lamborghini is shown pulling up to a stop sign',\n",
       " '8128, 0, a cartoon character from the spongebob squarepants speaks to the audience but no sounds is heard',\n",
       " '9056, 4, a british man driving a red car parks and upon switching the gear into reverse a rear camera pops out of the back of the car',\n",
       " '9056, 11, a man in a car is giving a review on a volkswagen car the car is red with what seems to be a leather interior',\n",
       " '9056, 18, a man on the wheels talking about the easiness of parking and the camera coming out of the logo when reverse gear is on for volkswagen polo',\n",
       " '9120, 8, in a black helmet and ski outfit is leaning forward and holding onto a white pole that is quickly pulling her over a field of snow',\n",
       " '9088, 9, a man in the blue shirt in the water with a surfboard and a shark fin near him right before he goes under']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"multiple_sentences[700].txt\", \"r\") as fo:\n",
    "    cleaned_sentences = fo.readlines()\n",
    "    cleaned_sentences = [line.strip().lower() for line in cleaned_sentences]\n",
    "    \n",
    "cleaned_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "new_video2caption_step4 = copy.deepcopy(new_video2caption_step3)\n",
    "\n",
    "for line in cleaned_sentences:\n",
    "    vid, sid, sent = line.strip().split(\", \")\n",
    "    vid, sid = int(vid), int(sid)\n",
    "    new_video2caption_step4[vid][sid] = sent\n",
    "\n",
    "for vid, sents in new_video2caption_step4.items():\n",
    "    if vid >= 7010:\n",
    "        continue\n",
    "    sents = [\" \".join(s.strip().split()[:18]) for s in sents]\n",
    "    new_video2caption_step4[vid] = sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step4_videodatainfo.json', 'w') as fo:\n",
    "    json.dump(new_video2caption_step4, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
